{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares (train set): 0.62\n",
      "Residual sum of squares: 32.35\n",
      "Residual sum of squares: 32.35\n",
      "32.7800580232\n",
      "R2 (test set): 0.56\n",
      "Residual sum of squares: 36.85\n",
      "Residual sum of squares: 36.85\n",
      "        Pred      lower      upper        duu        se\n",
      "0  25.006331  12.676546  37.336117  12.329785  0.018088\n",
      "9.1089376299\n",
      "RF test set MSE: 32.87\n",
      "[22.0] [ 26.0136] [32.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import pylab as pl # R2?\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = pd.read_csv('housing.csv')\n",
    "features = boston.drop('house_value' , 1).values\n",
    "y = boston['house_value'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.25, random_state=1978)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# R2 training\n",
    "print(\"Residual sum of squares (train set): %.2f\"\n",
    "      % lm.score(X_train,y_train))\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((lm.predict(X_train) - y_train) ** 2))\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % mean_squared_error(y_train, lm.predict(X_train)))\n",
    "\n",
    "n = X_train.shape[0]\n",
    "m = X_train.shape[1]\n",
    "\n",
    "# sum square\n",
    "s = np.sum((lm.predict(X_train) - y_train) ** 2)/(n-(m-1)-1) \n",
    "print(s)\n",
    "\n",
    "# standard deviation, square root of the diagonal of variance-co-variance matrix (sigular vector decomposition)\n",
    "# aka var_est\n",
    "sd_alpha = np.sqrt(s*(np.diag(np.linalg.pinv(np.dot(X_train.T,X_train))))) \n",
    "\n",
    "#print(type(sd_alpha\n",
    "#    ))\n",
    "#print(\"standard deviation: %.2f\"\n",
    "#      % np.sqrt(s*(np.diag(np.linalg.pinv(np.dot(X_train.T,X_train))))) )\n",
    "\n",
    "SE_est = np.sqrt(sd_alpha)\n",
    "#print(SE_est)\n",
    "\n",
    "#print(\"RSTD DEV: %.2f\"\n",
    "#      % SE_est)\n",
    "\n",
    "# Test set:\n",
    "\n",
    "# R2\n",
    "print(\"R2 (test set): %.2f\"\n",
    "      % lm.score(X_test,y_test))\n",
    "\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((lm.predict(X_test) - y_test) ** 2))\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % mean_squared_error(y_test, lm.predict(X_test)))\n",
    "\n",
    "\n",
    "class LRPI:\n",
    "    def __init__(self, normalize=False, n_jobs=1, t_value = 2.13144955): #  t value to get the 95% conf. interval.\n",
    "        self.normalize = normalize\n",
    "        self.n_jobs = n_jobs\n",
    "        self.LR = linear_model.LinearRegression(normalize=self.normalize, n_jobs= self.n_jobs)\n",
    "        self.t_value = t_value\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = pd.DataFrame(X_train)\n",
    "        self.y_train = pd.DataFrame(y_train)\n",
    "        \n",
    "        self.LR.fit(self.X_train, self.y_train)\n",
    "        X_train_fit = self.LR.predict(self.X_train)\n",
    "        self.MSE = np.power(self.y_train.subtract(X_train_fit), 2).sum(axis=0) / (self.X_train.shape[0] - self.X_train.shape[1] - 1)\n",
    "        self.X_train.loc[:, 'const_one'] = 1\n",
    "        self.XTX_inv = np.linalg.inv(np.dot(np.transpose(self.X_train.values) , self.X_train.values))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.X_test = pd.DataFrame(X_test)\n",
    "        self.pred = self.LR.predict(self.X_test)\n",
    "        self.X_test.loc[: , 'const_one'] =1\n",
    "        SE = [np.dot(np.transpose(self.X_test.values[i]) , np.dot(self.XTX_inv, self.X_test.values[i]) ) for i in range(len(self.X_test)) ]\n",
    "        results = pd.DataFrame(self.pred , columns=['Pred'])\n",
    "        \n",
    "        results.loc[:,\"lower\"] = results['Pred'].subtract((self.t_value)* (np.sqrt(self.MSE.values + np.multiply(SE,self.MSE.values) )),  axis=0)\n",
    "        results.loc[:,\"upper\"] = results['Pred'].add((self.t_value)* (np.sqrt(self.MSE.values + np.multiply(SE,self.MSE.values) )),  axis=0)\n",
    "        results.loc[:,\"duu\"] = (self.t_value)* (np.sqrt(self.MSE.values + np.multiply(SE,self.MSE.values) ))\n",
    "        results.loc[:,\"se\"] = SE\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    \n",
    "model = LRPI()\n",
    "model.fit(X_train, y_train)\n",
    "# save the model to disk\n",
    "filename = 'lm_model.sav'\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "#model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "a = X_test[1,]\n",
    "b = a.reshape(-1,len(a))\n",
    "\n",
    "results = model.predict(X_test[1:2,])\n",
    "#print(b) nää on samat\n",
    "#print(X_test[1:2,])\n",
    "print(results.head(10))\n",
    "\n",
    "# one-two-tree standard deviation\n",
    "\n",
    "print(np.std(y_test))\n",
    "\n",
    "## add a column of ones for the constant intercept term\n",
    "#X = np.vstack(( X_test, np.ones( X_test.size ) ))\n",
    "\n",
    "## convert the NumPy array to matrix\n",
    "#X = np.matrix( X )\n",
    " \n",
    "## perform the matrix multiplication,\n",
    "## and then take the inverse\n",
    "#C = np.linalg.inv( X * X.T )\n",
    " \n",
    "## multiply by the MSE of the residuals\n",
    "#C *= result.mse_resid\n",
    " \n",
    "## take the square root\n",
    "#SE = np.sqrt(C)\n",
    " \n",
    "#print SE\n",
    "\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "\n",
    "#rf = RandomForestRegressor(n_estimators=1000, min_samples_leaf=1)\n",
    "#rf.fit(X_train, y_train)\n",
    "# save the model to disk\n",
    "filename = 'rf_model.sav'\n",
    "#pickle.dump(rf, open(filename, 'wb'))\n",
    "\n",
    "rf = pickle.load(open(filename, 'rb'))\n",
    "print(\"RF test set MSE: %.2f\"\n",
    "      % np.mean((y_test - rf.predict(X_test))**2)) # MSE\n",
    "\n",
    "def pred_ints(model, X, percentile=95):\n",
    "    err_down = []\n",
    "    err_up = []\n",
    "    preds = []\n",
    "    for pred in model.estimators_:\n",
    "        preds.append(pred.predict(X)[0])\n",
    "    err_down.append(np.percentile(preds, (100 - percentile) / 2. ))\n",
    "    err_up.append(np.percentile(preds, 100 - (100 - percentile) / 2.))\n",
    "    return err_down, err_up\n",
    "\n",
    "a = X_test[1,]\n",
    "b = a.reshape(-1,len(a))\n",
    "\n",
    "\n",
    "err_down, err_up = pred_ints(rf, b)\n",
    "pred = rf.predict(b)\n",
    " \n",
    "print(err_down, pred, err_up)\n",
    "\n",
    "#truth = Y[idx[trainsize:]]\n",
    "#correct = 0.\n",
    "#for i, val in enumerate(truth):\n",
    "#    if err_down[i] <= val <= err_up[i]:\n",
    "#        correct += 1\n",
    "#print correct/len(truth)\n",
    "\n",
    "\n",
    "\n",
    "#sd_alpha = np.sqrt(s*(np.diag(np.linalg.pinv(np.dot(X.T,X))))) \n",
    "#print(sd_alpha)\n",
    "\n",
    "#predictions = lm.predict(X_test)\n",
    "\n",
    "#yb = boston.target.reshape(-1, 1)\n",
    "#Xb = boston['data'][:,5].reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "#regr = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "#regr.fit( Xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
